{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Label.csv file\n",
    "labels = pd.read_csv('../data/CICD/Label.csv')\n",
    "# Read the Data.csv file\n",
    "data = pd.read_csv('../data/CICD/Data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create X (features) and y (target)\n",
    "X = data\n",
    "y = labels['Label']\n",
    "\n",
    "# Create train/test split with 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Print the shapes of the resulting splits\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Testing labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=20, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': data.columns,\n",
    "    'importance': rf_classifier.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Plot confusion matrix\n",
    "class_names = sorted(labels['Label'].unique())\n",
    "plt.figure(figsize=(10, 8))\n",
    "plot_confusion_matrix(conf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plot_confusion_matrix(conf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "# Binarize the labels for ROC calculation\n",
    "y_test_bin = label_binarize(y_test, classes=class_names)\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], rf_classifier.predict_proba(X_test)[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves for each class\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %s' % (roc_auc[i], class_names[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curves for Each Class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Based on the confusion matrix, the pairs of classes that are most frequently confused with each other are:\")\n",
    "\n",
    "for i in range(len(conf_matrix)):\n",
    "    for j in range(len(conf_matrix)):\n",
    "        if i != j:\n",
    "            print(f\"* Class {class_names[i]} is confused with Class {class_names[j]} ({conf_matrix[i, j]} instances)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the confusion counts from the confusion matrix\n",
    "confused_pairs = []\n",
    "for i in range(len(conf_matrix)):\n",
    "    for j in range(len(conf_matrix)):\n",
    "        if i != j and conf_matrix[i, j] > 0:\n",
    "            confused_pairs.append(((class_names[i], class_names[j]), conf_matrix[i, j]))\n",
    "\n",
    "# Sort the confused pairs based on the number of instances in descending order\n",
    "confused_pairs_sorted = sorted(confused_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Pairs of classes that are most frequently confused with each other (in descending order):\")\n",
    "for (pair, count) in confused_pairs_sorted:\n",
    "    print(f\"* Class {pair[0]} is confused with Class {pair[1]} ({count} instances)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# 1. Feature importance analysis for class 5\n",
    "\n",
    "# Calculate permutation importance specifically for class 5\n",
    "result = permutation_importance(rf_classifier, X_test, y_test, \n",
    "                              n_repeats=10, \n",
    "                              random_state=42)\n",
    "\n",
    "# Create DataFrame of feature importance specifically for this problem\n",
    "class_importance = pd.DataFrame({\n",
    "    'feature': X_test.columns,\n",
    "    'importance': result.importances_mean\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features for Classification:\")\n",
    "print(class_importance.head(10))\n",
    "\n",
    "# 2. Analyze samples that are misclassified\n",
    "misclassified = X_test[y_test != y_pred]\n",
    "misclassified_true = y_test[y_test != y_pred]\n",
    "misclassified_pred = y_pred[y_test != y_pred]\n",
    "\n",
    "# Focus on class 5 misclassifications\n",
    "class_5_errors = misclassified[\n",
    "    (misclassified_true == 5) | (misclassified_pred == 5)\n",
    "]\n",
    "\n",
    "print(\"\\nStatistical summary of misclassified samples for class 5:\")\n",
    "print(class_5_errors.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Define custom class weights, increasing weight for class 5\n",
    "class_weights = {\n",
    "    0: 1,\n",
    "    1: 1,\n",
    "    2: 1,\n",
    "    3: 1,\n",
    "    4: 4,\n",
    "    5: 5,  # Increase weight for class 5\n",
    "    6: 1,\n",
    "    7: 1,\n",
    "    8: 1,\n",
    "    9: 1\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest Classifier with custom class weights\n",
    "rf_classifier_weighted = RandomForestClassifier(n_estimators=100,\n",
    "                                                 max_depth=20,\n",
    "                                                 class_weight=class_weights,\n",
    "                                                 random_state=42,\n",
    "                                                 n_jobs=-1)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_classifier_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_weighted = rf_classifier_weighted.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "print(\"Accuracy with Weighted Classes:\", accuracy_weighted)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report with Weighted Classes:\")\n",
    "print(classification_report(y_test, y_pred_weighted))\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance_weighted = pd.DataFrame({\n",
    "    'feature': data.columns,\n",
    "    'importance': rf_classifier_weighted.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features (Weighted):\")\n",
    "print(feature_importance_weighted.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "class_names = sorted(labels['Label'].unique())\n",
    "plt.figure(figsize=(10, 8))\n",
    "plot_confusion_matrix(conf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plot_confusion_matrix(conf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "experiment_name = \"CICD_IDS_Model\"\n",
    "mlflow.set_tracking_uri(\"http://192.168.1.86:5050\")\n",
    "\n",
    "# Asegura que el experimento exista o crÃ©alo\n",
    "if not mlflow.get_experiment_by_name(experiment_name):\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run RandomForest_Weighted at: http://192.168.1.86:5050/#/experiments/1/runs/c9398a1612414d97b277872d90fa0276\n",
      "ðŸ§ª View experiment at: http://192.168.1.86:5050/#/experiments/1\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/opt/mlflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     42\u001b[39m buffer.write(report_text)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Log the buffer as an artifact\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclassification_report.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Save and log feature importance\u001b[39;00m\n\u001b[32m     48\u001b[39m feature_importance_weighted = pd.DataFrame({\n\u001b[32m     49\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m'\u001b[39m: data.columns,\n\u001b[32m     50\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mimportance\u001b[39m\u001b[33m'\u001b[39m: rf_classifier_weighted.feature_importances_\n\u001b[32m     51\u001b[39m }).sort_values(\u001b[33m'\u001b[39m\u001b[33mimportance\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML-IDS/.venv/lib/python3.12/site-packages/mlflow/tracking/fluent.py:1251\u001b[39m, in \u001b[36mlog_text\u001b[39m\u001b[34m(text, artifact_file, run_id)\u001b[39m\n\u001b[32m   1223\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1224\u001b[39m \u001b[33;03mLog text as an artifact.\u001b[39;00m\n\u001b[32m   1225\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1248\u001b[39m \n\u001b[32m   1249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1250\u001b[39m run_id = run_id \u001b[38;5;129;01mor\u001b[39;00m _get_or_start_run().info.run_id\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML-IDS/.venv/lib/python3.12/site-packages/mlflow/tracking/client.py:2493\u001b[39m, in \u001b[36mMlflowClient.log_text\u001b[39m\u001b[34m(self, run_id, text, artifact_file)\u001b[39m\n\u001b[32m   2466\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, artifact_file: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2467\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Log text as an artifact.\u001b[39;00m\n\u001b[32m   2468\u001b[39m \n\u001b[32m   2469\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2491\u001b[39m \n\u001b[32m   2492\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2493\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_artifact_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtmp_path\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtmp_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2495\u001b[39m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/contextlib.py:144\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    146\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML-IDS/.venv/lib/python3.12/site-packages/mlflow/tracking/client.py:2447\u001b[39m, in \u001b[36mMlflowClient._log_artifact_helper\u001b[39m\u001b[34m(self, run_id, artifact_file)\u001b[39m\n\u001b[32m   2445\u001b[39m tmp_path = os.path.join(tmp_dir, filename)\n\u001b[32m   2446\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m tmp_path\n\u001b[32m-> \u001b[39m\u001b[32m2447\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML-IDS/.venv/lib/python3.12/site-packages/mlflow/tracking/client.py:2377\u001b[39m, in \u001b[36mMlflowClient.log_artifact\u001b[39m\u001b[34m(self, run_id, local_path, artifact_path)\u001b[39m\n\u001b[32m   2373\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_id.startswith(TRACE_REQUEST_ID_PREFIX):\n\u001b[32m   2374\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m   2375\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid run id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. `log_artifact` run id must map to a valid run.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2376\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2377\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML-IDS/.venv/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/client.py:926\u001b[39m, in \u001b[36mTrackingServiceClient.log_artifact\u001b[39m\u001b[34m(self, run_id, local_path, artifact_path)\u001b[39m\n\u001b[32m    924\u001b[39m     artifact_repo.log_artifacts(local_path, path_name)\n\u001b[32m    925\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m     \u001b[43martifact_repo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML-IDS/.venv/lib/python3.12/site-packages/mlflow/store/artifact/local_artifact_repo.py:43\u001b[39m, in \u001b[36mLocalArtifactRepository.log_artifact\u001b[39m\u001b[34m(self, local_file, artifact_path)\u001b[39m\n\u001b[32m     39\u001b[39m artifact_dir = (\n\u001b[32m     40\u001b[39m     os.path.join(\u001b[38;5;28mself\u001b[39m.artifact_dir, artifact_path) \u001b[38;5;28;01mif\u001b[39;00m artifact_path \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.artifact_dir\n\u001b[32m     41\u001b[39m )\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(artifact_dir):\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     45\u001b[39m     shutil.copy2(local_file, os.path.join(artifact_dir, os.path.basename(local_file)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML-IDS/.venv/lib/python3.12/site-packages/mlflow/utils/file_utils.py:211\u001b[39m, in \u001b[36mmkdir\u001b[39m\u001b[34m(root, name)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    210\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.errno != errno.EEXIST \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(target):\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML-IDS/.venv/lib/python3.12/site-packages/mlflow/utils/file_utils.py:208\u001b[39m, in \u001b[36mmkdir\u001b[39m\u001b[34m(root, name)\u001b[39m\n\u001b[32m    206\u001b[39m target = os.path.join(root, name) \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m root\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    210\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.errno != errno.EEXIST \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(target):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "    \u001b[31m[... skipping similar frames: makedirs at line 215 (1 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:225\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: '/opt/mlflow'"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "import io  # Import the io module\n",
    "\n",
    "# Set remote MLflow tracking URI\n",
    "mlflow.set_tracking_uri(\"http://192.168.1.86:5050\")\n",
    "\n",
    "# Ensure experiment exists or create it\n",
    "mlflow.set_experiment(\"CICD_IDS_Model_v2\")\n",
    "\n",
    "# Start a new run\n",
    "with mlflow.start_run(run_name=\"RandomForest_Weighted\"):\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"max_depth\", 20)\n",
    "    mlflow.log_param(\"class_weight\", class_weights)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"n_jobs\", -1)\n",
    "\n",
    "    # Define and train pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', rf_classifier_weighted)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate and log metric\n",
    "    y_pred_weighted = pipeline.predict(X_test)\n",
    "    accuracy_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_weighted)\n",
    "\n",
    "    # Generate classification report and log it as an artifact\n",
    "    report_text = classification_report(y_test, y_pred_weighted)\n",
    "    \n",
    "    # Use io.StringIO to create an in-memory text buffer\n",
    "    buffer = io.StringIO()\n",
    "    buffer.write(report_text)\n",
    "    \n",
    "    # Log the buffer as an artifact\n",
    "    mlflow.log_text(buffer.getvalue(), \"classification_report.txt\")\n",
    "\n",
    "    # Save and log feature importance\n",
    "    feature_importance_weighted = pd.DataFrame({\n",
    "        'feature': data.columns,\n",
    "        'importance': rf_classifier_weighted.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    feature_importance_weighted.to_json(\"feature_importance.json\", orient=\"records\", indent=2)\n",
    "    mlflow.log_artifact(\"feature_importance.json\")\n",
    "\n",
    "    # Log pipeline and register it\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=pipeline,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"CICD_IDS_Model\"\n",
    "    )\n",
    "\n",
    "    print(\"âœ… Model, metrics and artifacts logged to remote MLflow.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
